# CAP6415_F25_project-Energy_Cost_Prediction_for_Ground_Robots_Using_Multimodal_Sensing

Unmanned ground vehicles (UGV) can be utilized for various purposes including agricultural use, transportation, or environmental monitoring to name a few. Since UGVs, such as the one used in this project, operate on battery power, it can only travel a certain distance before needing a battery recharge. If the battery/energy requirement a UGV needs is unknown, unexpected mission failures or incomplete tasks may occur. Although one can measure the complete distance or time a UGV can travel before running out of battery, it would be time consuming to measure its battery capabilities when running over various surfaces, as the energy consumption will vary depending on each type of surface. In this work, we present a method capable of predicting a UGVs battery/energy consumption when running over various terrains. This will be done by training a neural network on environment data from a camera as well as other sensor data obtained from the UGV when traveling through a specific terrain. To obtain environmental data, a camera will be used to capture images of the terrain that the UGV will be traveling through. Additionally, data from various other sensors located on the UGV, such as inertial measurement unit, GPS data, and battery data will be used as inputs to train the neural network. Our method consists of using a pretrained convolutional neural network, such as ResNet18, for the image data obtained from the camera. Additionally, we will utilize a multilayer perception model to be trained on both the image data and numerical data obtained from the other sensors, in order to predict the UGVs energy consumption when navigating through varying terrains. In this way, a UGVs battery consumption can be predicted and known despite the terrain it travels through. For the purposes of this course project, the camera system and camera data collection along with training the neural network will be the main focus of this project as this is most applicable to the course content. The codes utilized within this project draw inspiration from the code examples found from the following Github page: https://github.com/IntelRealSense/librealsense.git as well as the notebook named “Notebook_03 - RNN and CNN Introduction” provided within the CAP 6415 Computer Vision course. Additionally, due to GitHub file size limitations, the camera image datasets for the training dataset and test dataset are not saved in this repository. Instead, the training camera data can be downloaded from the following Google Drive link: https://drive.google.com/file/d/1BOzPzSa9JfQhPgA2VVJGOS4Zd6M1qP3w/view?usp=sharing and the test camera data can be downloaded from the following Google Drive link: https://drive.google.com/file/d/1D0K8JSMLcnGIXFMUYeFlR7Wp4wnADxyg/view?usp=sharing. 
